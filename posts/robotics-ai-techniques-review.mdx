---
title: "OMSCS CS7638 - Robotics: AI Techniques Course Review"
description: ""
date: "2024-06-22"
tags: ['OMSCS','self-learning']
---

I started the OMSCS journey at Georgia Tech in Spring 2024. I originally wanted to take both Computational Photography and this course, but the workload was too intense so I dropped CP promptly. It turned out that RAIT is a great course to get a taste of this program and the pace/workload is definitely suitable for someone working fulltime. I'd like to showcase the assignments I've worked on during this course, which are all combinations of cool concepts + fun graphics + hours of tuning!

## Kalman Filter - HopScotch

When you're stranded in the galaxy and you can only navigate via jumps, suddenly there's a shower of asteroids coming by, what do you do? Sounds like a perfect setup for hitchhiking. But how do we know where the asteroids are going to be in the next second? Well if you're an astronaut who knows Kalman Filter you're in luck. At the high level, Kalman Filter takes the current observation and **predict** the position of each asteroid for the next timestep using the motion model, and then use the observation from the next timestep to **correct** the prediction. This part of the project is basically creating the KF matrixes and feeding the current observations to the algorithm. In the next part we have to decide which asteroid to hop on, which is limited by the jumping range and world bounds. To get home faster, the velocity of the asteroid is also an important variable to consider. This is what it looks like when the spaceship hopstoches thru the galaxy and gets home safely:  

<figure className="flex justify-center items-center">
  <img
    src="/rait/kf.gif"
    alt="kalman-filter-result-gif"
  />
</figure>


## Particle Filter - Solar Systems
After an important mission, you successfully ride a satelite home. However, when you were released into your home solar system, you lost track of where you are and only have the gravimeter readings (gravitational pull from all the planets in the solar system) to rely on. This is where the particle filter comes in: 
You first initialize a number of "pseudo satelites" aka particles, and assign a weight, which is the probability of the particle being sampled from the probability density function, to each particle, resample the particles, add fuzz to the particles, mimic the motion of the target, and finally estimate the position of the target in the next timestep. It sounds like a lot of steps but it's suprisingly easy to code. Take a look at how the particles collapse and track the target (the red dot):  
<figure className="flex justify-center items-center">
  <img
    src="/rait/pf.gif"
    alt="particle-filter-result-gif"
  />
</figure>

## Search - Warehouse
Coming back from the space, you're now a robotics controller at a warehouse. You have to design an algorithm that allows the robot to pick up and drop off boxes effcifiently. There are three scenarios to consider: robot has fixed starting position and you need to find the optimal delivery path for multiple boxes; robot starts at random positions and you need you find the optimal delivery path for **any** starting position; and the last one is similar to the second but robot moves with errors, which means sometimes it means to go left but there's a chance it errs and goes to the other direction.
For the first scenario, A* is used which calls for exploration of different heuristics that estimates the distance from the robot to the goal. For the other two, we're asked to implement value iteration, which is a tenichque that looks for a converged value thru reptitions. Basically we need to consider all possible robot states and initialize value to each state depending on the problem (in this case a minimizing problem). We then go thru sweeps (loop thru each robot position and record the value aka cost to transition to the next position) and update the value table. Eventually we exit the sweep when the delta hits under the threshold. Conceptually VI is a bit harder to grasp than other algorithms, but I think it's a fantastic example of dynamic programming and a novel way to solve pathfinding problems. I recommend going thru solutions to examples like [this taxi problem](https://www.gymlibrary.dev/environments/toy_text/taxi/) or [frozen lake problem](https://www.gymlibrary.dev/environments/toy_text/frozen_lake/) before tackling this part of the project.  

Check out how the robot moves along the "minimum cost" path generated by VI:
<figure>
      <img
        className="mx-auto"
        src="/rait/search-policy.gif"
        alt="search-policy-result-gif"
      />
    <figcaption style={{textAlign:'center'}}>Delivery path generated by VI</figcaption>
</figure>  

<figure>
    <img
      className="mx-auto"
      src="/rait/search-astar.gif"
      alt="search-astar-result-gif"
    />
    <figcaption style={{textAlign:'center'}}>Delivery path generated by A*</figcaption>
</figure>

## PID - Drone controller
The goal of this project is to design a PID controller that generates thrust and roll for the drone to move vertically and horizontally. Once we reach the target we need to hover there. The three parameters we need to tune and finalize are tau_p - proportional gain used to adjust the proportional output, tau_i - integral gain used to adjust the integral output, and tau_d adjust the derivative output. By summing the three ouputs we find the optimal thrust or roll angle for the drone to reach the steady state. 


<figure>
    <img
      className="mx-auto"
      src="/rait/pid.gif"
      alt="pid-result-gif"
    />
</figure>

## SLAM - Indiana Drones
The final project utilizes Graph SLAM tenichque to track the location of the drone and simultaneously estimate the location of the surrounding trees. There's also an extra part where you need to detect whether a treasure in within reach and extract it. This is the most linear algebra heavy part of the whole course. In Graph SLAM, robot and tree locations are represented as nodes and sensor measurements (distance between drone and trees) edges. The information matrix Omega is crucial in this algorithm. Whenever a new robot position is recorded or new landmark spotted, it gets expanded and the state vector Xi that represents estimates of robot and landmark positions gets updated accordingly.
It took me a while to understand the construction process of both the matrix and vector, which involves expansion and extraction of the matrix, and the coding doesn't come as naturally as other projects for me either. I think it would be helpful to refresh basic linear algebra before going through the lectures. Here's what it looks like when the drone successfully detects and extracts the treasure (red triangle):

<figure>
    <img
      className="mx-auto"
      src="/rait/slam.gif"
      alt="slam-gif"
    />
</figure>

## Conclusion
I learnt a lot about classic robotic tracking and path planning techniques in this course. The TAs are super engaging and supportive which unfornately isn't the norm for an online program. They react to the forum questions fast and the grade feedback never gets delayed. The lead TA Chris gave supplementary lectures for newbies like me and I think they're crucial for cracking the projects. I spent on average 13 hours each week and got an A (96%) in the end. Overall the experience was fun and fulfilling, except the time where you have to juggle midterm, PID project AND search project :), and I recommend everyone who's starting out to take this course! 